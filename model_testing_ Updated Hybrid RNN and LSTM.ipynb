{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "rnn_model = load_model(r\"D:\\Project_Env\\News Article classification\\News Article classification\\Save_model\\news_classification_model_rnn.h5\")\n",
    "lstm_model=load_model(r\"D:\\Project_Env\\News Article classification\\News Article classification\\Save_model\\News_classNews_classification_model_LSTM_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_THRESHOLD = 20  # Number of tokens (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load pre-trained embeddings (ensure the correct file path)\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(r\"D:\\Project_Env\\News Article classification\\News Article classification\\data\\numberbatch-en.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding_vector(text, word_vectors, embedding_dim=300, max_length=200):\n",
    "    tokens = text.split()\n",
    "    embeddings = [word_vectors[word] for word in tokens if word in word_vectors]\n",
    "\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros((max_length, embedding_dim), dtype=np.float32)\n",
    "\n",
    "    embeddings = np.array(embeddings[:max_length], dtype=np.float32)\n",
    "    padding_needed = max_length - len(embeddings)\n",
    "\n",
    "    if padding_needed > 0:\n",
    "        embeddings = np.vstack([embeddings, np.zeros((padding_needed, embedding_dim), dtype=np.float32)])\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded!\n",
      "Index(['class_index', 'title', 'description', 'text', 'clean_text', 'vector'], dtype='object')\n",
      "Index(['class_index', 'title', 'description', 'text', 'clean_text', 'vector'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "SAVE_TRAIN_PATH = r\"D:\\Project_Env\\News Article classification\\News Article classification\\data\\train.pkl\"\n",
    "SAVE_TEST_PATH = r\"D:\\Project_Env\\News Article classification\\News Article classification\\data\\test.pkl\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load training data\n",
    "with open(SAVE_TRAIN_PATH, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# Load test data\n",
    "with open(SAVE_TEST_PATH, \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "print(\"Data successfully loaded!\")\n",
    "print(train_data.keys())\n",
    "print(test_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique class indexes: [3 4 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Check unique class indexes in the dataset\n",
    "unique_classes = train_data[\"class_index\"].unique()\n",
    "print(\"Unique class indexes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n"
     ]
    }
   ],
   "source": [
    "label_map = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "Predicted class: World\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Predicted class: Business\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "Predicted class: Sci/Tech\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Predicted class: Sports\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Predicted class: Sci/Tech\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "Predicted class: Sci/Tech\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "Predicted class: Sci/Tech\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load pre-trained model\n",
    "model = load_model(r\"D:\\Project_Env\\News Article classification\\News Article classification\\Save_model\\News_classification_model_LSTM_1.h5\")\n",
    "\n",
    "# Mapping class indexes to category names\n",
    "label_map = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "while True:\n",
    "    # Take user input\n",
    "    new_text = input(\"\\nEnter a news article (or type 'exit' to quit): \")\n",
    "    \n",
    "    # Exit condition\n",
    "    if new_text.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Convert text to embedding\n",
    "    X_new = np.array([get_embedding_vector(new_text, word_vectors)], dtype=np.float32)\n",
    "\n",
    "    # Predict class probabilities\n",
    "    predictions = model.predict(X_new)\n",
    "\n",
    "    # Predict class index\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]  # Extract single value\n",
    "\n",
    "    # Get class name\n",
    "    predicted_class_name = label_map[predicted_class_index]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# # Load both models\n",
    "# rnn_model = load_model(r\"C:\\Users\\Trisha\\jupytor tutorial\\Final-Year-Project\\News Article classification\\saved_model\\news_classification_model_rnn.h5\")\n",
    "# lstm_model = load_model(r\"C:\\Users\\Trisha\\jupytor tutorial\\Final-Year-Project\\News Article classification\\saved_model\\news_classification_model.h5\")\n",
    "\n",
    "# # Category index mapping\n",
    "# class_labels = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "# # Define threshold\n",
    "# LENGTH_THRESHOLD = 50\n",
    "\n",
    "# Prediction function\n",
    "def hybrid_predict(text, word_vectors, rnn_model, lstm_model, threshold=50):\n",
    "    tokens = text.split()\n",
    "    embedding = get_embedding_vector(text, word_vectors)\n",
    "    input_data = np.expand_dims(embedding, axis=0)\n",
    "\n",
    "    if len(tokens) <= threshold:\n",
    "        prediction = rnn_model.predict(input_data)\n",
    "        model_used = \"RNN\"\n",
    "    else:\n",
    "        prediction = lstm_model.predict(input_data)\n",
    "        model_used = \"LSTM\"\n",
    "\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return label_map[predicted_class], model_used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Predicted class: Business (RNN)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "Predicted class: World (RNN)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Predicted class: Sports (LSTM)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Predicted class: Sports (LSTM)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "Predicted class: Sports (RNN)\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Take user input\n",
    "    new_text = input(\"\\nEnter a news article (or type 'exit' to quit): \")\n",
    "    \n",
    "    # Exit condition\n",
    "    if new_text.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Check input length\n",
    "    tokens = new_text.split()\n",
    "    X_new = np.array([get_embedding_vector(new_text, word_vectors)], dtype=np.float32)\n",
    "\n",
    "    # Choose model based on input length\n",
    "    if len(tokens) <= 20:\n",
    "        predictions = rnn_model.predict(X_new)\n",
    "        model_used = \"RNN\"\n",
    "    else:\n",
    "        predictions = lstm_model.predict(X_new)\n",
    "        model_used = \"LSTM\"\n",
    "\n",
    "    # Predict class\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class_name = label_map[predicted_class_index]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class_name} ({model_used})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
