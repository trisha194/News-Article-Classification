{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":954242,"sourceType":"datasetVersion","datasetId":518517},{"sourceId":11262217,"sourceType":"datasetVersion","datasetId":7039151}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:57:01.144023Z","iopub.execute_input":"2025-04-03T17:57:01.144221Z","iopub.status.idle":"2025-04-03T17:57:02.482875Z","shell.execute_reply.started":"2025-04-03T17:57:01.144201Z","shell.execute_reply":"2025-04-03T17:57:02.481924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define file paths\nSAVE_TRAIN_PATH = '/kaggle/input/training-the-model/train.pkl'\nSAVE_TEST_PATH = \"/kaggle/input/training-the-model/test.pkl\"\n\nimport pickle\n\n# Load training data\nwith open(SAVE_TRAIN_PATH, \"rb\") as f:\n    train_data = pickle.load(f)\n\n# Load test data\nwith open(SAVE_TEST_PATH, \"rb\") as f:\n    test_data = pickle.load(f)\n\nprint(\"Data successfully loaded!\")\nprint(train_data.keys())\nprint(test_data.keys())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:59:02.546346Z","iopub.execute_input":"2025-04-03T17:59:02.546660Z","iopub.status.idle":"2025-04-03T17:59:06.499408Z","shell.execute_reply.started":"2025-04-03T17:59:02.546636Z","shell.execute_reply":"2025-04-03T17:59:06.498714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gensim\n\n# Define the path to the embeddings file\nfile_path = '/kaggle/input/conceptnet/numberbatch-en-19.08.txt'\n\n# Load the ConceptNet Numberbatch word vectors\nword_vectors = gensim.models.KeyedVectors.load_word2vec_format(file_path, binary=False)\n\n# Example: Get the vector for the word 'apple'\napple_vector = word_vectors['apple']\nprint(apple_vector)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:00:23.216351Z","iopub.execute_input":"2025-04-03T18:00:23.216771Z","iopub.status.idle":"2025-04-03T18:02:10.980639Z","shell.execute_reply.started":"2025-04-03T18:00:23.216737Z","shell.execute_reply":"2025-04-03T18:02:10.979688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def embedding_generator(text_data, word_vectors, batch_size=32):\n    for i in range(0, len(text_data), batch_size):\n        batch_texts = text_data[i : i + batch_size]\n        batch_embeddings = [get_embedding_vector(text, word_vectors) for text in batch_texts]\n        yield np.array(batch_embeddings, dtype=np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:02:54.445445Z","iopub.execute_input":"2025-04-03T18:02:54.445723Z","iopub.status.idle":"2025-04-03T18:02:54.449850Z","shell.execute_reply.started":"2025-04-03T18:02:54.445701Z","shell.execute_reply":"2025-04-03T18:02:54.449034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_gen = embedding_generator(train_data[\"text\"], word_vectors)\ntest_gen = embedding_generator(test_data[\"text\"], word_vectors)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:04:15.540826Z","iopub.execute_input":"2025-04-03T18:04:15.541174Z","iopub.status.idle":"2025-04-03T18:04:15.551759Z","shell.execute_reply.started":"2025-04-03T18:04:15.541147Z","shell.execute_reply":"2025-04-03T18:04:15.551006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\nfrom tensorflow.keras.utils import Sequence\nimport gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:07:37.409665Z","iopub.execute_input":"2025-04-03T18:07:37.410017Z","iopub.status.idle":"2025-04-03T18:07:37.421401Z","shell.execute_reply.started":"2025-04-03T18:07:37.409989Z","shell.execute_reply":"2025-04-03T18:07:37.420571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimized Data Generator\nclass TextDataGenerator(Sequence):\n    def __init__(self, texts, labels, word_vectors, batch_size=32, max_length=200):\n        self.texts = texts\n        self.labels = labels\n        self.word_vectors = word_vectors\n        self.batch_size = batch_size\n        self.max_length = max_length\n        self.embedding_dim = word_vectors.vector_size\n        \n        # Pre-convert all texts to embedding indices to speed up batch generation\n        self.preprocessed = [self.text_to_embeddings(text) for text in texts]\n\n    def text_to_embeddings(self, text):\n        tokens = text.split()[:self.max_length]\n        return [self.word_vectors.key_to_index[word] for word in tokens if word in self.word_vectors]\n\n    def __len__(self):\n        return int(np.ceil(len(self.texts) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_texts = self.preprocessed[idx*self.batch_size : (idx+1)*self.batch_size]\n        batch_labels = self.labels[idx*self.batch_size : (idx+1)*self.batch_size]\n\n        # Pad sequences and create embeddings matrix\n        X_batch = np.zeros((len(batch_texts), self.max_length, self.embedding_dim), dtype=np.float32)\n        for i, text_indices in enumerate(batch_texts):\n            if text_indices:\n                X_batch[i, :len(text_indices)] = self.word_vectors.vectors[text_indices]\n\n        # Convert labels to categorical (assuming classes are 1-4)\n        y_batch = tf.keras.utils.to_categorical(np.array(batch_labels) - 1, num_classes=4)\n        \n        return X_batch, y_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:08:41.555731Z","iopub.execute_input":"2025-04-03T18:08:41.556105Z","iopub.status.idle":"2025-04-03T18:08:41.562824Z","shell.execute_reply.started":"2025-04-03T18:08:41.556072Z","shell.execute_reply":"2025-04-03T18:08:41.562132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create generators\ntrain_generator = TextDataGenerator(\n    train_data[\"text\"], \n    train_data[\"class_index\"], \n    word_vectors,\n    batch_size=64  # Increased batch size for better GPU utilization\n)\n\ntest_generator = TextDataGenerator(\n    test_data[\"text\"],\n    test_data[\"class_index\"],\n    word_vectors,\n    batch_size=64\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:09:03.664903Z","iopub.execute_input":"2025-04-03T18:09:03.665249Z","iopub.status.idle":"2025-04-03T18:09:07.250710Z","shell.execute_reply.started":"2025-04-03T18:09:03.665225Z","shell.execute_reply":"2025-04-03T18:09:07.250022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimized Model Architecture\nmodel = Sequential([\n    Bidirectional(LSTM(128, return_sequences=True), input_shape=(200, 300)),\n    Bidirectional(LSTM(64)),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(4, activation='softmax')\n])\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:09:36.395324Z","iopub.execute_input":"2025-04-03T18:09:36.395614Z","iopub.status.idle":"2025-04-03T18:09:39.850348Z","shell.execute_reply.started":"2025-04-03T18:09:36.395590Z","shell.execute_reply":"2025-04-03T18:09:39.849661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create train and test generators\ntrain_generator = TextDataGenerator(train_data[\"text\"], train_data[\"class_index\"], word_vectors, batch_size=32)\ntest_generator = TextDataGenerator(test_data[\"text\"], test_data[\"class_index\"], word_vectors, batch_size=32)\n\n# Use the generator in model training\nmodel.fit(train_generator, validation_data=test_generator, epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:12:44.594755Z","iopub.execute_input":"2025-04-03T18:12:44.595129Z","iopub.status.idle":"2025-04-03T18:53:17.828743Z","shell.execute_reply.started":"2025-04-03T18:12:44.595098Z","shell.execute_reply":"2025-04-03T18:53:17.827983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('/kaggle/working/news_classification_model.h5')  # Saves in the working directory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:01:49.344648Z","iopub.execute_input":"2025-04-03T19:01:49.345004Z","iopub.status.idle":"2025-04-03T19:01:49.437209Z","shell.execute_reply.started":"2025-04-03T19:01:49.344971Z","shell.execute_reply":"2025-04-03T19:01:49.436474Z"}},"outputs":[],"execution_count":null}]}